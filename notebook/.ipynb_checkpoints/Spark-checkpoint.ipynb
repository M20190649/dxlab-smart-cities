{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>jupyter-spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=jupyter-spark>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark in a nutshell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[353, 807, 740, 972, 421]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do something to prove it works\n",
    "rdd = sc.parallelize(range(1000))\n",
    "rdd.takeSample(False, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPS Log File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load RDD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7882\n",
      "7882\n",
      "7882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16869.0, 122.48572579667099)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "def distance(origin, destination):\n",
    "    lat1, lon1 = origin[\"lat\"], origin[\"lon\"]\n",
    "    lat2, lon2 = destination[\"lat\"], destination[\"lon\"]\n",
    "    radius = 6371 # km\n",
    "\n",
    "    dlat = radians(lat2-lat1)\n",
    "    dlon = radians(lon2-lon1)\n",
    "    a = sin(dlat/2) * sin(dlat/2) + cos(radians(lat1)) \\\n",
    "        * cos(radians(lat2)) * sin(dlon/2) * sin(dlon/2)\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "def parseLogLine(line):\n",
    "    line = line.strip().split(\",\")    \n",
    "    date = line[5] + \" \" + line[6]\n",
    "    return {\n",
    "        \"lat\": float( line[0] ), \n",
    "        \"lon\": float( line[1] ),\n",
    "        \"ts\" : datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\").timestamp()\n",
    "    }\n",
    "\n",
    "def isNotHeader(line):\n",
    "    a = line.split(\",\")\n",
    "    return True if len(a) == 7 else False\n",
    "\n",
    "\n",
    "def locTS(location):\n",
    "    return location['ts']\n",
    "    \n",
    "\n",
    "def t_duration(traceRDD):\n",
    "    timestampsRDD = traceRDD.map( locTS )\n",
    "    duration = timestampsRDD.max() - timestampsRDD.min()\n",
    "    return duration\n",
    "\n",
    "\n",
    "def t_origin(traceRDD):\n",
    "    ts_origin = traceRDD.map( locTS ).min()\n",
    "    originRDD = traceRDD.filter( lambda loc: loc[\"ts\"] == ts_origin )\n",
    "    origin = originRDD.collect()[0]\n",
    "    return origin\n",
    "\n",
    "\n",
    "def t_destination(traceRDD):\n",
    "    ts_destin = traceRDD.map( locTS ).max()\n",
    "    destinRDD = traceRDD.filter( lambda loc: loc[\"ts\"] == ts_destin )\n",
    "    destin = destinRDD.collect()[0]\n",
    "    return destin\n",
    "\n",
    "\n",
    "def t_origin_destination(traceRDD):\n",
    "    origin = t_origin(traceRDD)\n",
    "    destin = t_destination(traceRDD)\n",
    "    return (origin, destin)\n",
    "\n",
    "\n",
    "def durationAsString(duration):\n",
    "    return str(timedelta(seconds=duration) )\n",
    "    \n",
    "file = 'data/010/Trajectory/20080618003409.plt'\n",
    "\n",
    "rdd  = sc.textFile( file )\n",
    "data = rdd.filter( isNotHeader ).map( parseLogLine ).sortBy( locTS )\n",
    "\n",
    "### Checar si hay puntos repetidos\n",
    "print(data.count())\n",
    "print(data.map(lambda loc: (loc[\"lat\"], loc[\"lon\"], loc[\"ts\"]) ).distinct().count())\n",
    "print(data.groupBy(lambda loc: loc[\"ts\"]).count())\n",
    "\n",
    "\n",
    "time = t_duration(data)\n",
    "orig = t_origin( data )\n",
    "dest = t_destination( data )\n",
    "dist = distance(orig, dest)\n",
    "\n",
    "time, dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609637\n",
      "609455\n",
      "607439\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hacer cleansing\n",
    "\n",
    "data = sc.textFile( 'data/010/Trajectory/*' ).filter( isNotHeader ).map( parseLogLine ).sortBy( locTS )\n",
    "\n",
    "# decir de que tamanio es la coleccion antes d ehacer el heatmap. \n",
    "# Explicar que hay que reducir la coleecion\n",
    "print(data.count())\n",
    "print(data.map(lambda loc: (loc[\"lat\"], loc[\"lon\"], loc[\"ts\"]) ).distinct().count())\n",
    "print(data.groupBy(lambda loc: loc[\"ts\"]).count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[1071] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cruzar puntos con etiquetas\n",
    "# analizis de etiquetas\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "def parseLabelsLine(line):\n",
    "    tokens = line.split(\"\\t\")    \n",
    "    start_time = datetime.strptime( tokens[0], \"%Y/%m/%d %H:%M:%S\").timestamp()\n",
    "    end_time   = datetime.strptime( tokens[1], \"%Y/%m/%d %H:%M:%S\").timestamp()\n",
    "    label = tokens[2]\n",
    "    return (start_time, end_time, label)\n",
    "\n",
    "\n",
    "def notLabelsHeader(line):\n",
    "    return line.startswith( 'Start Time' ) == False\n",
    "\n",
    "\n",
    "def locInTrajectory( label_loc ):\n",
    "    label = label_loc[0]\n",
    "    loc   = label_loc[1]\n",
    "    start_time = label[0]\n",
    "    end_time   = label[1]\n",
    "    return True if start_time <= loc['ts'] and loc['ts'] <= end_time else False\n",
    "\n",
    "\n",
    "labelsRDD = sc.textFile( 'data/010/labels.txt' )\n",
    "labelsRDD = labelsRDD.filter( notLabelsHeader ).map( parseLabelsLine )\n",
    "\n",
    "logRDD = sc.textFile( 'data/010/Trajectory/20080618003409.plt' )\n",
    "logRDD = logRDD.filter( isNotHeader ).map( parseLogLine ).sortBy( locTS )\n",
    "\n",
    "\n",
    "Trajectory = namedtuple('Trajectory', ['start', 'end', 'mode', 'locs'])\n",
    "\n",
    "trajectories = labelsRDD.cartesian( logRDD ).filter( locInTrajectory ).groupByKey()\n",
    "trajectories = trajectories.map( lambda t: Trajectory(\n",
    "    start= t[0][0],\n",
    "    end  = t[0][1],\n",
    "    mode = t[0][2],\n",
    "    locs = t[1]\n",
    "))\n",
    "\n",
    "trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.resultiterable.ResultIterable"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories.count()\n",
    "\n",
    "data = trajectories.filter( lambda tj: tj.mode == 'train' ).map( lambda tj: tj.locs ).collect()[0]\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('taxi', 532), ('subway', 355), ('walk', 179), ('train', 5804), ('walk', 234), ('bus', 712), ('bus', 66)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7882, 7882)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = trajectories.map( lambda tj: (tj.mode, len(tj.locs)) ).collect()\n",
    "print(x)\n",
    "\n",
    "l = []\n",
    "for e in x:\n",
    "    l.append(e[1])\n",
    "\n",
    "sum(l), logRDD.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae38d3e3645c434fbe2cc230bf50b562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Figure</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Figure()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = gmaps.figure()\n",
    "\n",
    "locs = []\n",
    "for loc in data:\n",
    "    locs.append( (loc['lat'], loc['lon']) )\n",
    "\n",
    "layer = gmaps.heatmap_layer(locs)\n",
    "fig.add_layer( layer )\n",
    "\n",
    "\n",
    "#heatmap_layer = gmaps.heatmap_layer(locations)\n",
    "#fig.add_layer(heatmap_layer)\n",
    "#markers = gmaps.marker_layer(locations=locations, info_box_content=[\"origine\", \"destination\"])\n",
    "#fig.add_layer(markers)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eec39fff64d41b5ba1ec12858f3e875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Figure</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Figure()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gmaps\n",
    "gmaps.configure(api_key=\"AIzaSyBVGIwiga847RsDpucrpR5M5KAs7Zj1_nE\")\n",
    "\n",
    "fig = gmaps.figure()\n",
    "\n",
    "locations = [ (orig['lat'], orig['lon']), (dest['lat'], dest['lon']) ]\n",
    "\n",
    "#heatmap_layer = gmaps.heatmap_layer(locations)\n",
    "#fig.add_layer(heatmap_layer)\n",
    "\n",
    "markers = gmaps.marker_layer(locations=locations, info_box_content=[\"origine\", \"destination\"])\n",
    "fig.add_layer(markers)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef6867093fd4f98b6d5b6eb4bee54da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Figure</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Figure()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gmaps\n",
    "gmaps.configure(api_key=\"AIzaSyBVGIwiga847RsDpucrpR5M5KAs7Zj1_nE\")\n",
    "\n",
    "fig = gmaps.figure()\n",
    "\n",
    "locations = [ (loc[\"lat\"], loc[\"lon\"]) for loc in data.collect() ]\n",
    "\n",
    "heatmap_layer = gmaps.heatmap_layer(locations)\n",
    "fig.add_layer(heatmap_layer)\n",
    "\n",
    "#markers = gmaps.marker_layer(locations)\n",
    "#fig.add_layer(markers)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring Single File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In spark, you can load a file using the ```sc.textFile()``` operation. Note how this operation returns an RDD (Resiliable Distributed Dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"data/010/Trajectory/20070804033032.plt\")\n",
    "type(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A distributed dataset is equivalent to a list. Lets see the first 10 elements in the RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the first 6 lines of the file are metadata. Lets filter the metadata by keeping only the lines that contains **locations**. A location in the file is a line composed of 7 attributes, each separated by comma. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNotHeader(line):\n",
    "    a = line.split(\",\")\n",
    "    if len(a) == 7:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "filtered_lines = lines.filter( isNotHeader )\n",
    "filtered_lines.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now locations are strings. We need to parse them so that we can operate over them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def parseLocation(line):\n",
    "    loc = line.strip().split(\",\")\n",
    "    lat = float( loc[0] )\n",
    "    lon = float( loc[1] )\n",
    "    date = loc[5]+ \" \" + loc[6]\n",
    "    date = datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return ( lat, lon, date )\n",
    "\n",
    "locations = filtered_lines.map( parseLocation )\n",
    "locations.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With locations in this format, we can do some interesting stuffs. For instance, lets compute the duration of the trayectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = locations.map( \n",
    "    lambda loc: loc[2].timestamp() \n",
    ")\n",
    "\n",
    "start_time = timestamps.min()\n",
    "end_time   = timestamps.max()\n",
    "\n",
    "duration = int( end_time - start_time )\n",
    "\n",
    "'Duration: ' + str( duration ) + ' seg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the first and last timestamps, we can identify their respective locations and thus, compute the distance.\n",
    "https://www.movable-type.co.uk/scripts/latlong.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "def distance(origin, destination):\n",
    "    lat1, lon1 = origin[0], origin[1]\n",
    "    lat2, lon2 = destination[0], destination[1]\n",
    "    radius = 6371 # km\n",
    "\n",
    "    dlat = radians(lat2-lat1)\n",
    "    dlon = radians(lon2-lon1)\n",
    "    a = sin(dlat/2) * sin(dlat/2) + cos(math.radians(lat1)) \\\n",
    "        * cos(radians(lat2)) * sin(dlon/2) * sin(dlon/2)\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d\n",
    "\n",
    "loc1 = (39.921712, 116.472343)\n",
    "loc2 = (39.902885, 116.4213)\n",
    "\n",
    "dist = distance(loc1, loc2)\n",
    "str(dist) + ' km'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets complete our RDD with distance and duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "locations.map( lambda loc: (\n",
    "    loc[0], loc[1], loc[2]\n",
    ")).take(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initial_location = locations.filter( lambda loc: loc[2].timestamp() == start_time )\n",
    "final_location   = locations.filter( lambda loc: loc[2].timestamp() == end_time )\n",
    "\n",
    "loc_1 = initial_location.collect()[0]\n",
    "loc_n = final_location.collect()[0]\n",
    "\n",
    "distance(loc_1, loc_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring all user trayectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPS logs are organized per users. Lets load all the logs of a specific user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parseLocation(line):\n",
    "    loc = line.strip().split(\",\")\n",
    "    lat = float( loc[0] )\n",
    "    lon = float( loc[1] )\n",
    "    date = loc[5]+ \" \" + loc[6]\n",
    "    date = datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\").timestamp()\n",
    "    return ( lat, lon, date )\n",
    "\n",
    "\n",
    "def t_origin_destination(trajectory):\n",
    "    timestamps = trajectory.map( lambda loc: loc[2] )\n",
    "    ts_origin = timestamps.min()\n",
    "    ts_destin = timestamps.max()\n",
    "    origin = trajectory.filter( lambda loc: loc[2] == ts_origin )\n",
    "    destin = trajectory.filter( lambda loc: loc[2] == ts_destin )\n",
    "    return (origin.collect()[0], destin.collect()[0])\n",
    "\n",
    "   \n",
    "def t_distance(trajectory):\n",
    "    (origine, destination) = t_origin_destination(trajectory)\n",
    "    return distance (origine, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from os import listdir, stat, remove\n",
    "import os\n",
    "\n",
    "USER = '010'\n",
    "PATH = 'data/{0}/Trajectory'.format( USER )\n",
    "\n",
    "files = []\n",
    "\n",
    "for file in os.listdir(PATH):\n",
    "    files.append( file )\n",
    "    \n",
    "\n",
    "    \n",
    "def load_trajectory(file):\n",
    "    lines = sc.textFile(file)\n",
    "    filtered_lines = lines.filter( isNotHeader )\n",
    "    locations = filtered_lines.map( parseLocation )\n",
    "    return locations\n",
    "\n",
    "\n",
    "\n",
    "tmp = [ (load_trajectory( 'data/{0}/Trajectory/{1}'.format( USER, f)), f) for f in files ]\n",
    "\n",
    "user_trajectories = sc.parallelize(tmp)\n",
    "\n",
    "'''\n",
    "user_trajectories = sc.parallelize([])\n",
    "for t in tmp:\n",
    "    user_trajectories = user_trajectories.union(t)\n",
    "\n",
    "\n",
    "user_trajectories.map( lambda loc: (\n",
    "    loc[0],\n",
    "    loc[1]\n",
    ")).take(2)\n",
    "'''\n",
    "#user_trajectories[0].count(), user_trajectories[1].count(), user_trajectories[0].union( user_trajectories[1] ).count()\n",
    "\n",
    "user_trajectories.map( lambda traj: t_distance(traj) )\n",
    "\n",
    "user_trajectories.take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load trajectory \n",
    "linesRDD = sc.textFile(\"data/010/Trajectory/20070804033032.plt\")\n",
    "\n",
    "# Remove file header\n",
    "def isNotHeader(line):\n",
    "    a = line.split(\",\")\n",
    "    if len(a) == 7:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "rdd = linesRDD.filter( isNotHeader )\n",
    "\n",
    "''' Compact version\n",
    "rdd = linesRDD.filter(\n",
    "    lambda line: len(line.split(\",\")) == 7\n",
    ")\n",
    "'''\n",
    "\n",
    "print( rdd.take(5) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import time\n",
    "\n",
    "# we are not using altitude in this example\n",
    "\n",
    "def parse(line):\n",
    "    a = line.split(\",\")\n",
    "    lat = float( a[0] )\n",
    "    lon = float( a[1] )\n",
    "    date = a[5]+ \" \" + a[6]\n",
    "    ts   = time.strptime(date, \"%Y-%m-%d %H:%M:%S\") \n",
    "    \n",
    "    return {\n",
    "        \"lat\": lat, \n",
    "        \"lon\": lon,\n",
    "        \"ts\": calendar.timegm( ts )\n",
    "    }\n",
    "\n",
    "\n",
    "'''\n",
    "GPS_logs = GPS_logs.map(\n",
    "    lambda line: {\n",
    "        \"latitude\":  float(line.split(\",\")[0]),\n",
    "        \"longitude\": float(line.split(\",\")[1]),\n",
    "        \"altitude\":  float(line.split(\",\")[3]),\n",
    "        \"timestamp\": datetime.strptime(line.split(\",\")[5] + \" \" + line.split(\",\")[6], \"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    ")\n",
    "'''\n",
    "\n",
    "pointsRDD = rdd.map( parse )\n",
    "\n",
    "print (pointsRDD.take(5))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values\n",
    "\n",
    "pointsRDD.sortBy(\n",
    "    lambda point: point['ts']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "tssRDD = pointsRDD.map(\n",
    "    lambda point : point['ts']\n",
    ")\n",
    "\n",
    "x = tssRDD\n",
    "#print( x.take(10) )\n",
    "\n",
    "s = tssRDD.stats()\n",
    "print('Min ts: ' + str(s.min()))\n",
    "print('Max ts: ' + str( s.max()) )\n",
    "print('Duration: ' + str( s.max()-s.min()) )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "path = 'data/{}/Trajectory/{}.plt'.format('010', '20070804155303') \n",
    "\n",
    "def parseLogLine(line):\n",
    "    # Split line after removing '\\n'\n",
    "    tokens = line.strip().split(\",\")\n",
    "    \n",
    "    # Parse latitude and longitude \n",
    "    lat = float( tokens[0] )\n",
    "    lon = float( tokens[1] )        \n",
    "    # Parse date-time\n",
    "    \n",
    "    date = '{} {}'.format(tokens[5], tokens[6])    \n",
    "    ts   = datetime.strptime(date, '%Y-%m-%d %H:%M:%S').timestamp()    \n",
    "    \n",
    "    return [ lat, lon, ts ]\n",
    "\n",
    "\n",
    "def parseLogFile(log):\n",
    "    log = log.split('\\n')[7:1]\n",
    "    return [ parseLogLine(line) for line in log ]\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "with open(path, 'r') as f:\n",
    "    content = f.read()\n",
    "    parseLogFile( content )\n",
    "    \n",
    "f.closed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "_data = data.collect()\n",
    "\n",
    "center = _data[0]\n",
    "m = folium.Map(location=[ center['lat'], center['lon']])\n",
    "\n",
    "_data = [ _data[i] for i in range(1,500000) ]\n",
    "\n",
    "\n",
    "locations = [ [loc[\"lat\"], loc[\"lon\"]] for loc in _data ]\n",
    "HeatMap( locations ).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def parseLogFile(log):\n",
    "    log = log.split('\\n')[7:]\n",
    "    return [ parseLogLine(line) for line in log[:1] ]\n",
    "        \n",
    "\n",
    "exp = '.*/(\\d.*)/Trajectory/(\\d*).plt'\n",
    "\n",
    "        \n",
    "rdd = sc.wholeTextFiles('data/010/Trajectory/*')\n",
    "\n",
    "rdd = rdd.map( lambda x: (\n",
    "    ( re.match(exp, x[0]).group(1), re.match(exp, x[0]).group(2) ), \n",
    "    parseLogFile(x[1])\n",
    "))\n",
    "\n",
    "\n",
    "rdd = rdd.flatMapValues( lambda x: x )\n",
    "\n",
    "rdd = rdd.map( lambda x: (\n",
    "    x[0][0],\n",
    "    x[0][1],\n",
    "    x[1][0],\n",
    "    x[1][1],\n",
    "    x[1][2]\n",
    ") )\n",
    "\n",
    "print( rdd.take(3) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_str = 'file:/home/jovyan/data/010/Trajectory/20081223230455.plt'\n",
    "\n",
    "x = re.match('.*/data/(\\d.*)/Trajectory/(\\d*).plt', _str)\n",
    "\n",
    "print( x.group(1, 2) ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all USER trayectories \n",
    "from datetime import datetime\n",
    "\n",
    "def parseLogLine(line):\n",
    "    # Split line after removing '\\n'\n",
    "    _line = line.strip().split(\",\")\n",
    "    \n",
    "    # Parse latitude and longitude \n",
    "    lat = float( _line[0] )\n",
    "    lon = float( _line[1] )        \n",
    "\n",
    "    # Parse date-time\n",
    "    date = '{} {}'.format(_line[5], _line[6])\n",
    "    ts   = datetime.strptime(date, '%Y-%m-%d %H:%M:%S').timestamp()    \n",
    "    \n",
    "    return ( lat, lon, ts )\n",
    "    \n",
    "    \n",
    "\n",
    "def load_user_trajectory(user, trajectory):\n",
    "    \n",
    "    # Load file\n",
    "    path = 'data/{}/Trajectory/{}.plt'.format(user, trajectory) \n",
    "    rdd = sc.textFile( path )\n",
    "    \n",
    "    # Remove header\n",
    "    rdd = rdd.filter(\n",
    "        lambda line: len(line.split(\",\")) == 7\n",
    "    )\n",
    "\n",
    "    # Parse file lines\n",
    "    rdd = rdd.map( parseLogLine )\n",
    "    \n",
    "    # Produce tuples (usr, trj, lat, lon, ts)\n",
    "    rdd.map(\n",
    "        lambda loc : (user, trajectory, loc[0], loc[1], loc[2])\n",
    "    )\n",
    "    \n",
    "    return rdd\n",
    "\n",
    "    \n",
    "def load_user_trajectories(user):\n",
    "    \n",
    "    path = 'data/{}/Trajectory'.format(user)\n",
    "    \n",
    "    rdd = None\n",
    "    for trajectory in listdir(path):\n",
    "        tmp = load_user_trajectory(user, trajectory)\n",
    "        if rdd not None: \n",
    "            rdd.union( tmp )\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "'''\n",
    "    rdd = linesRDD.filter(\n",
    "    lambda line: len(line.split(\",\")) == 7\n",
    ")    \n",
    "    \n",
    "from os import listdir, stat, remove\n",
    "from os.path import isfile, join, exists\n",
    "\n",
    "PATH  = \"data/010/Trajectory\"\n",
    "\n",
    "for t_file in listdir(PATH):\n",
    "    FULL_PATH = join(PATH, t_file)\n",
    "    rdd = sc.textFile(FULL_PATH)\n",
    "    print( rdd.count() )\n",
    "    if userDir.isdigit() and not isfile(userDir):\n",
    "        user       = userDir\n",
    "        inputPath  = join(INPUT,  userDir)\n",
    "        outputPath = join(OUTPUT, userDir)\n",
    "\n",
    "        if exists(join(INPUT, \"labels.txt\")):\n",
    "            extractUserTrayectories(user, inputPath, outputPath)\n",
    "            cleanUserDir(outputPath)\n",
    "'''\n",
    "\n",
    "\n",
    "xxx = loadTrajectoryRDD('010', '20070804033032')\n",
    "xxx.take(2)\n",
    "\n",
    "zzz = loadTrajectoryRDD('010', '20070804155303')\n",
    "zzz.take(2)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractUserTrayectories(userID, basePath):\n",
    "\n",
    "    labelsFilePath = basePath + \"/labels.txt\"\n",
    "    logsPath = basePath + \"/Trajectory\"\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # --  Step 1: Load Labels (Trajectories META-DATA)\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    labels = sc.textFile(labelsFilePath)\n",
    "\n",
    "    # Remove file header\n",
    "    labels = labels.filter(\n",
    "        lambda line: not \"Start\" in line\n",
    "    )\n",
    "\n",
    "    labels = labels.map(\n",
    "        lambda line: {\n",
    "            \"start_time\": datetime.strptime(line.split(\"\\t\")[0], \"%Y/%m/%d %H:%M:%S\"),\n",
    "            \"end_time\":   datetime.strptime(line.split(\"\\t\")[1], \"%Y/%m/%d %H:%M:%S\"),\n",
    "            \"transportation_mode\": line.split(\"\\t\")[2]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # --    Step 2: Load GPS logs\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    GPS_logs = sc.textFile(logsPath)\n",
    "\n",
    "    # Remove file header\n",
    "    GPS_logs = GPS_logs.filter(\n",
    "        lambda line: len(line.split(\",\")) == 7\n",
    "    )\n",
    "\n",
    "    GPS_logs = GPS_logs.map(\n",
    "        lambda line: {\n",
    "            \"latitude\":  float(line.split(\",\")[0]),\n",
    "            \"longitude\": float(line.split(\",\")[1]),\n",
    "            \"altitude\":  float(line.split(\",\")[3]),\n",
    "            \"timestamp\": datetime.strptime(line.split(\",\")[5] + \" \" + line.split(\",\")[6], \"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # -- Step 3: Find trajectories\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    CR = labels.cartesian(GPS_logs)\n",
    "\n",
    "    CR = CR.filter(\n",
    "        lambda t: t[0][\"start_time\"] <= t[1][\"timestamp\"] and t[0][\"end_time\"] >= t[1][\"timestamp\"]\n",
    "    )\n",
    "\n",
    "    GR = CR.groupBy(\n",
    "        lambda t: (t[0][\"start_time\"], t[0][\"end_time\"], t[0][\"transportation_mode\"])\n",
    "    )\n",
    "\n",
    "    Trayectories = GR.map(\n",
    "        lambda t: {\n",
    "            \"transportationMode\": t[0][2],\n",
    "            \"startTime\": t[0][0],\n",
    "            \"endTime\":   t[0][1],\n",
    "            \"coordinates\": [z[1] for z in t[1]]\n",
    "        }\n",
    "    ) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels():\n",
    "    \n",
    "    labels = sc.textFile(\"data/105/labels.txt\")\n",
    "\n",
    "    # Remove 1st line in file\n",
    "    labels = labels.filter(\n",
    "        lambda line: not \"Start Time\" in line\n",
    "    )\n",
    "    \n",
    "    print( labels.take(10) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os import listdir, stat, remove\n",
    "from os.path import isfile, join, exists\n",
    "\n",
    "labels()\n",
    "\n",
    "#extractUserTrayectories(104, \"data/104\")\n",
    "'''\n",
    "INPUT  = \"data/104\"\n",
    "for userDir in listdir(INPUT):\n",
    "    user = userDir\n",
    "    inputPath = join(INPUT, userDir)\n",
    "    print(inputPath)\n",
    "   '''\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( sc.textFile(\"data/104/labels.txt\").take(10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
